\documentclass[a4paper,12pt,twoside]{scrreprt}
% Autor der Vorlage: Klaus Rheinberger, FH Vorarlberg
% 2017-02-20

%% Hilfe: z.B.
% empfohlener Einstieg: http://latex.tugraz.at/
% https://de.wikibooks.org/wiki/LaTeX-Kompendium:_Schnellkurs:_Erste_Schritte
% https://de.wikibooks.org/wiki/LaTeX-Kompendium:_Schnellkurs
% https://de.wikibooks.org/wiki/LaTeX-Kompendium

%% Pakete:
% Der Befehl \usepackage[latin9]{inputenc} ermöglicht die direkte Angabe von Umlauten. Übrigens lässt sich so auch das Euro-Zeichen direkt eingeben. Auf Betriebssystemen, wie zum Beispiel allen neueren Linux-Distributionen, verwendet man statt \usepackage[latin9]{inputenc} besser \usepackage[utf8]{inputenc}, auf Applesystemen verwendet man \usepackage[macce]{inputenc} (oder das für ältere Modelle gültige \usepackage[applemac]{inputenc}).
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}    % Silbentrennung bei Sonderzeichen
\usepackage{graphicx}	    % Bilder einbinden
\usepackage[english]{babel} % Deutsche Sprachanpassungen
\usepackage{csquotes}	    % When using babel or polyglossia with biblatex, loading csquotes is recommended to ensure that quoted texts are typeset according to the rules of your main language.
\usepackage{acronym}  % für optionales Abkürzungsverzeichnis
\usepackage{eurosym}  % z. B. \EUR{12345,68}
\usepackage[linktocpage=true]{hyperref} % Links z. B. \href{https://www.wikibooks.org}{Wikibooks home}
\usepackage[bindingoffset=8mm]{geometry}% Bindeverlust von 8mm einbeziehen. Mit dem geometry-Paket können Sie die Ränder auch ganz individuell anpassen.
\usepackage{caption} % Abbildungslegenden
\captionsetup{format=hang, justification=raggedright}
\usepackage{placeins}
\usepackage{float} % prevent LaTeX table repositioning

% sql formatting
\usepackage{listings}
\usepackage{xcolor}
\lstdefinestyle{sql}{
  language=SQL,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue}\bfseries,
  commentstyle=\color{gray},
  stringstyle=\color{orange},
  morekeywords={SELECT, FROM, WHERE, JOIN, AND, OR, EXISTS, BETWEEN, AS, ON,
      HAVING},
  breaklines=true,
  frame=single,
  captionpos=b
}

% for sub figures
\usepackage{subcaption}

\usepackage{amsfonts}

\usepackage[a-2b,mathxmp]{pdfx}[2018/12/22]

\usepackage[style=ieee,citestyle=ieee,backend=biber]{biblatex}
% Literaturverweise
%\usepackage[style=numeric,citestyle=numeric,backend=biber]{biblatex}
% biblatex comes with a variety of built-in bibliography/citation style families (numeric, alphabetic, authoryear, authortitle, verbose), and there's a growing number of custom styles:
% https://de.sharelatex.com/learn/Biblatex_citation_styles
% https://de.sharelatex.com/learn/Biblatex_bibliography_styles
\addbibresource{references.bib}
\addbibresource{Bachelor_Thesis_GPS_Classification/Bachelor_Thesis_GPS_Classification.bib}
% Anstatt die Bibtex-Datei selber zu erstellen, kann sie z. B. aus einer Zotero-Sammlung zu BibTeX exportiert werden.

%% Einstellungen:
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{2}   % Tiefe der Gliederung im In haltsverzeichnis

%% ERSETZEN VON ECKIGEN KLAMMERN:
% Ersetzen Sie den Text in den eckigen Klammern!

\begin{document}

% evtl. Sperrvermerkseite
% \thispagestyle{empty}

% \noindent
% [Achtung: Verwenden Sie einen Sperrvermerk nur in sehr gut begründeten Fällen
% ]

% \section*{[evtl. Sperrvermerk]}   % evtl. ersetzen durch \section*{Sperrvermerk}
% Die vorliegende Arbeit ist bis zum [DATUM] für die öffentliche Nutzung zu
% sperren. Veröffentlichung, Vervielfältigung und Einsichtnahme sind ohne meine
% ausdrückliche Genehmigung nicht gestattet. Der Titel der Arbeit sowie das
% Kurzreferat/Abstract dürfen veröffentlicht werden.

% \vspace{3cm}

% \noindent Dornbirn, \hfill Unterschrift Verfasser*in

% Titelblatt:
% \newpage\mbox{}\newpage
\cleardoublepage   % force output to a right page
\thispagestyle{empty}
\begin{titlepage}
  \begin{flushright}
    \includegraphics[width=0.4\linewidth]{Abbildungen/Wort-Bild-Marke-cmyk}
    % https://www.fhv.at/fh/presse/logo-bildmaterial
  \end{flushright}
  \begin{flushleft}
    \section*{Classification of GPS Track Data Using Machine Learning Methods}
    \subsection*{A Case Study of Waste Collection Vehicles}
    \vspace{1cm}

    Bachelor thesis\\
    for obtaining the academic degree
    \vspace{0.5cm}

    \textbf{Bachelor of Science in Engineering (BSc)}

    \vspace{1cm}
    Vorarlberg University of Applied Sciences\newline
    Computer Science - Software and Information Engineering

    \vspace{0.5cm}

    Supervised by\newline
    Dipl.-Ing. Dr. techn. Ralph Hoch

    \vspace{0.5cm}

    Submitted by\newline
    Matthias Hefel\newline
    Dornbirn, May 2025
  \end{flushleft}
\end{titlepage}

% evtl. Widmung:
\newpage

\section*{Dedication}

\vspace{1cm}
\begin{center}
  \emph{Dedicated to my younger self, who found a fascination in writing
    software from
    a young age and decided to follow his dreams!}\\[0.5cm]
  \emph{And to my parents, who wholeheartedly supported me throughout this
    journey.}\\[0.5cm]
  \textbf{Thank you.}
\end{center}
\vspace{1cm}

% Kurzreferat:
\newpage
\section*{Kurzreferat}

\subsection*{Klassifizierung von GPS-Spurdaten mit Machine Learning Methoden am
  Beispiel von Abfallsammelfahrzeugen}

In der Abfallwirtschaft ist die strategische Tourenplanung ein zentraler
Prozess, bei dem durch eine effiziente Gebietsaufteilung eine optimale
Auslastung der Fahrzeugflotte bei gleichzeitiger Minimierung der Kosten
erreicht werden soll. Gerade bei der Planung von Einsätzen in neuen,
unbekannten Gebieten sind Entsorgungsunternehmen jedoch häufig mit
Unsicherheiten konfrontiert, da Erfahrungswerte fehlen und viele
planungsrelevante Annahmen geschätzt werden müssen.

In dieser Arbeit wird untersucht, wie vorhandene GPS-Tracking-Daten von
Abfallsammelfahrzeugen genutzt werden können, um die strukturellen Merkmale
von
Gebieten automatisch zu klassifizieren. Ziel ist es, aus bekannten Gebieten
Muster zu extrahieren, die Rückschlüsse auf die räumliche Struktur (z.B.
städtisch vs. ländlich) zulassen und somit als Grundlage für Vergleiche mit
neuen
Gebieten dienen können.

Zu diesem Zweck wurde ein auf maschinellem Lernen basierendes System
entwickelt, das
GPS-Wegpunktdaten verarbeitet, Merkmale extrahiert, die Daten mit einem
semi-supervised clustering Verfahren strukturiert und anschließend ein
Klassifikationsmodell trainiert, das neue Datensätze automatisch
klassifiziert. Die Klassifizierung
wird in vier Strukturklassen durchgeführt: \texttt{URBAN},
\texttt{SUBURBAN}, \texttt{TOWN} und \texttt{RURAL}.

Das Klassifikationsmodell wurde in eine API eingebettet, die eine einfache
Anbindung an bestehende Softwarelösungen ermöglicht. Eine automatisierte
Klassifizierung kann durch die Angabe einer
Tracking-ID durchgeführt werden.

Langfristig bildet diese Arbeit somit die Grundlage für eine ausbaufähige
Lösung, bei der auch geografische Strukturdaten (z.B. aus OpenStreetMap) in
in die Analyse einbezogen werden, um robuste Vergleichsmöglichkeiten zwischen
auf
bekannten und neuen Gebieten zu schaffen. Die vollständige Integration dieser
zusätzlichen Datenquellen ist jedoch nicht Teil dieser Bachelorarbeit
, sondern bleibt zukünftigen Arbeiten vorbehalten.

% OLD ABSTRACT:

% In der Abfallwirtschaft ist die strategische Tourenplanung ein wichtiger
% Prozess, in dem durch optimale Gebietsaufteilung eine maximal effiziente
% Fuhrparkauslastung bei möglichst geringen Kosten ermittelt wird. Dies geschieht
% in Entsorgungsbetrieben sowohl für bestehende Auftragsgebiete, als auch bei der
% Kalkulation von neuen Ausschreibungen. Vor Allem bei Regionen, in denen keine
% Erfahrungswerte vorliegen müssen für eine robuste Tourenplanung zahlreiche
% unscharfe Annahmen getroffen und manchmal auch Schätzungen vorgenommen werden.
% Um diese Unsicherheiten durch die Analyse von geographischen Strukturen zur
% verringern soll eine Technologie in die bestehende Tourenplanungssoftware der
% Firma integriert werden, die folgende Aufgabenstellung automatisiert lösen
% kann: Anhand von bestehenden GPS-Aufzeichnungen sollen strukturelle
% Eigenschaften der jeweilige Sammelgebiete numerisch bewertet und klassifiziert
% werden. Gleichermaßen sollen anhand von geographischen (und möglichst frei
% verfügbaren Strukturdaten) aus noch unbekannten Gebieten erhoben werden können
% um diese auf die selbe Art und Weise klassifizieren zu können. Dadurch entsteht
% einerseits eine Referenzdatenmenge (von bestehenden Sammeltouren) und eine
% Vergleichsdatenmenge (aus den neuen Ausschreibungsgebieten). Dort wo die
% Klassifizierungsdaten übereinstimmen, kann davon ausgegangen werden, dass die
% planungsrelevanten Kennzahlen aus bestehenden Auftragsgebieten ohne gewagte
% Annahmen einfach übernommen werden können. Die Klassifizierung von GPS-Daten
% und geographischen Strukturdaten soll mit Hilfe von künstlicher Intelligenz
% automatisiert erstellt werden können. Auch die Überlegung, welche
% geographischen Strukturdaten denn überhaupt aussagekräftig sind um einen
% Vergleich anzustreben, sollen ggf. mit Hilfe von KI Technologien erfolgen.

% Das Ziel der praktischen Arbeit ist es einen Sandbox-Service zu implementieren,
% der von der bestehenden Software der \textit{infeo GmbH} aufgerufen und mit
% Daten befüllt
% werden kann um so "auf Knopfdruck" Klassifizierungen und Vergleiche von
% GPS-Daten und Ausschreibungs-Strukturdaten zu erstellen. Die Anwender:innen
% haben dadurch die Möglichkeit für neue Ausschreibungen entsprechend passende
% Planungsparameter aus ihren bestehenden Auftragsgebieten zu berechnen und somit
% die Unsicherheiten bei der Ausschreibungskalkulation deutlich zu reduzieren.

\vspace{0.5cm}

\noindent
GPS-Datenklassifizierung, Abfallwirtschaft, Künstliche Intelligenz,
Geografische Datenanalyse, Maschinelles Lernen, Automatisierung

% Abstract:
\newpage
\section*{Abstract}
\subsection*{Classification of GPS Track Data Using Machine Learningn Methods:
  A Case Study of
  Waste Collection Vehicles}

% In waste management, efficient route planning is crucial for minimizing
% operational costs and improving service delivery. Particularly when bidding for
% new service areas without prior operational experience, planners face
% significant uncertainty. One way to reduce this is by comparing new areas to
% structurally similar regions based on movement data from existing operations.

% This thesis presents a machine learning-based approach to classify GPS track
% data of waste collection vehicles into structural categories such as urban,
% suburban, town, and rural. A comprehensive feature extraction pipeline was
% implemented to capture both geometric and behavioral characteristics of each
% route. These features were used to train a Random Forest classifier

% To enable real-world use, the trained model was deployed through a
% FastAPI-based web service. The API allows external systems, such as the
% existing software of \textit{infeo GmbH}, to request a classification of a
% given GPS tracking in real time. This modular component serves as a first step
% toward the broader goal of matching structural patterns in unfamiliar regions,
% thereby reducing uncertainty in route planning and tender bid calculations.

% While the classification of unknown areas based on external geospatial data
% remains a future goal, this thesis delivers a working foundation that
% demonstrates the feasibility and practical value of data-driven structural
% analysis using only GPS data.

% OLD ABSTRACT:
In waste management, strategic route planning is a central
process in which an efficient allocation of areas is intended to achieve
optimal
utilization of the vehicle fleet while minimizing costs. However, waste
management companies are often faced with uncertainties, especially when
planning operations in new, unknown areas, as
experience is lacking and many planning-relevant assumptions have to be
estimated.

This work investigates how existing GPS tracking data from
waste collection vehicles can be used to automatically classify the structural
characteristics of
areas. The aim is to extract
patterns from known areas that allow conclusions to be drawn about the spatial
structure (e.g.
urban vs. rural) and can thus serve as a basis for comparisons with new
areas.

To this end, a machine learning-based system was developed that processes
GPS waypoint data, extracts features, structures the data using a
semi-supervised clustering method and then trains a
classification model that automatically classifies new data sets. The
classification is carried out in four structure classes: \texttt{URBAN},
\texttt{SUBURBAN}, \texttt{TOWN} and \texttt{RURAL}.

The classification model was embedded in an API that enables a simple
connection to existing software solutions. Automated classification can be
carried out by specifying a
tracking ID.

In the long term, this work thus forms the basis for an expandable
solution in which geographical structural data (e.g. from OpenStreetMap) is
also included in
the analysis in order to create robust comparison options between areas known
to
and new areas. However, the complete integration of these
additional data sources is not part of this bachelor project,
but is reserved for future work.
\vspace{0.5cm}

\noindent
GPS Data Classification, Waste Management, Artificial Intelligence, Geographic
Data Analysis, Machine Learning, Automation

% evtl. Vorwort:
% \newpage
% \section*{Preface}   % evtl. ersetzen durch \section*{Widmung}

%  [Preface Text]

% Inhaltsverzeichnis:
\cleardoublepage   % force output to a right page
\tableofcontents

\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{List of Figures}
\listoffigures

\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{List of Tables}
\listoftables

% evtl. Abkürzungsverzeichnis:
\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{List of Abbreviations}
% evtl. ersetzen durch \addcontentsline{toc}{chapter}{Abkürzungsverzeichnis}
\chapter*{List of Abbreviations}
\begin{acronym}[WGS84]
  \acro{AI}{Artificial Intelligence}
  \acro{API}{Application Programming Interface}
  \acro{CSV}{Comma-Separated Values}
  \acro{PKL}{Python Pickle File}
  \acro{DBSCAN}{Density-Based Spatial Clustering of Applications with Noise}
  \acro{DACH}{Germany (D), Austria (A), and Switzerland (CH)}
  \acro{F1-score}{Harmonic Mean of Precision and Recall}
  \acro{GIS}{Geographic Information System}
  \acro{GPS}{Global Positioning System}
  \acro{JSON}{JavaScript Object Notation}
  \acro{ML}{Machine Learning}
  \acro{OSM}{OpenStreetMap}
  \acro{PCA}{Principal Component Analysis}
  \acro{RF}{Random Forest}
  \acro{SHAP}{SHapley Additive exPlanations}
  \acro{URL}{Uniform Resource Locator}
  \acro{WGS84}{World Geodetic System 1984}
\end{acronym}

\chapter{Introduction}

\begin{quote}
  \textit{``The world's most valuable resource is no longer oil, but data''}
  \cite{noauthor_worlds_nodate}
\end{quote}
In today's digital age, where electronic devices are a part of everyone's daily
lives, increasing amounts of data
are being generated every day, and this trend shows no signs of slowing down.
\cite{petroc_data_nodate}
With this increase in data, businesses ranging across all industries recognize
the importance of leveraging it for decision-making and operational efficiency.
This has lead to a growing demand for technologies that can gather insights
from
data and integrate seamlessly into strategic processes.

One industry in which data-driven decision-making is becoming increasingly
important is the
waste management industry.

\section{Motivation}
\begin{quote}
  \textit{
    ``The Europe Waste Management Market size was valued at USD 116.21
    billion in
    2023, and is predicted to reach USD 169.37 billion by 2030, at a CAGR of
    4.5\% from 2024 to 2030.''\cite{noauthor_europe_nodate}}
\end{quote}

Such growth reflects the increasing need for scalabe, efficient and sustainable
waste
management practices, in response to rising waste volumes across urban,
suburban and rural areas \cite{noauthor_solid_nodate}.

The waste management sector is considered critical infrastructure and is under
growing pressure to adapt to personnel shortages, blackouts, and rising costs.
In many cases, the only viable solution is to optimize and automate operational
processes. Digital transformation plays a key role in making day-to-day
operations significantly more robust and
efficient.\cite{noauthor_gemeinsam_nodate}
In this context, the application of machine learning and data analytics
promises to enhance strategic planning and reduce operational uncertainty.

This thesis is conducted in collaboration with \textit{infeo GmbH}, a software
company specialized in digital transformation in the waste management
sector. Their mission emphasizes the need to improve existing infrastructure
with innovative tools:

\begin{quotation}
  \textit{
    ``Die Abfallwirtschaft ist ein systemkritischer Wirtschaftsbereich und
    zählt
    zur kritischen Infrastruktur. Die Branche muss sich vor Personalausfällen,
    Blackouts und Kostensteigerungen schützen. Das gelingt oft nur durch
    Automatisierung und Optimierung von Prozessen, die das Tagesgeschäft
    maßgeblich robuster und effektiver machen.
    ''\cite{noauthor_gemeinsam_nodate}}
\end{quotation}

\section{Problem Statement}

Companies operating in the waste collection business have trouble calculating
accurate cost estimates for new service areas when expanding their field of
business into
areas with no prior operational data.
They
often have to make assumptions and rough estimates on several paramters
concerning the operation cost in new service areas. A data driven estimation
can help create more accurate and less risky assessments for unknown collection
locations. This can help reduce uncertainties and improve the accuracy of bid
calculations.
Since GPS tracking data is already collected in existing service
areas, there is potential to extract meaningful patterns from this data to
support more accurate decision-making in new contexts.

\section{Solution Approach and Goal}

The primary goal of this thesis is to explore how GPS tracking data from waste
collection vehicles can be analysed to gain meaningful insight and
automatically classified to support better planning decisions.

To achieve this, a machine learning pipeline was developed that
involves extracting meaningful features from GPS waypoint data, applying
semi-supervised clustering in order to group similar trackings, assigning
interpretable labels (eg., \texttt{URBAN}, \texttt{SUBUBRBAN}, \texttt{TOWN}
and
\texttt{RURAL}) based on structural characteristics and training a supervised
classification model to automate label prediction for new data.
The resulting classifier was built into an API, allowing classification of any
given tracking via an API endpoint given its tracking ID.

While the long-term vision proposed by \textit{infeo GmbH} involves a service
for full automation of planning parameter suggestions for new geofences, based
on OpenStreetMap and internal tracking data, this thesis focuses on building a
foundational component: the GPS-based route classification system.

\section{Structure of the Work}

The remainder of this thesis is structured in the following chapters:

\begin{itemize}
  \item \textbf{Chapter 2: Background and Related Work: } Provides an overview
        of the technical and scientific basis relevant for this thesis.
  \item \textbf{Chapter 3: Problem Definition and Solution approach:}
        Introduces the core problem addressed by the thesis, describes the
        dataset
        used, and outlines the solution approach.
  \item \textbf{Chapter 4: Implementation:} Provides a detailed description of
        how the previously introduced methods and algorithms were implemented.
        This
        includes the data preprocessing, feature extraction, clustering
        pipeline and
        classifier training.
  \item \textbf{Chapter 5: Evaluation and Discussion:} Presents the results of
        the clustering and classification. Performance metrics, visualizations,
        and
        analysis of the results are discussed alongside future research and
        application.
  \item \textbf{Chapter 6: Conclusion:} Summarization of the contributions of
        the thesis, highlighting key takeaways and shortcomings.
\end{itemize}

\chapter{Background and Related Work}
This chapter provides an overview of the technical and scientific basis
relevant for this thesis.
Relevant methods include feature extraction to gain meaningful information
from GPS data, clustering algorithms for unsupervised learning and related work
showing approaches to similar problems. The presented work builds upon already
existing methods by combining
clustering and classification to identify structural properties of waste
collection routes from GPS trackings.

\section{Technical Background}
In order to develop a system that can analyse and classify structural patterns
in GPS data, it is necessary to understand how geographic data can be
transformed into meaningful features and how to leverage them by applying
machine learning techniques.
This section outlines the key technical components that support this thesis.

\subsection{Feature Engineering for Geographic data}
Geospatial data, composed of sequential latitude and longitude points,
is not inherently suitable for machine learning and requires transformation
into numerical features to be suitable for machine learning.
Key features commonly used in literature include: speed, acceleration, bearing
and distance between consecutive points~\cite{etemad_predicting_2018}.
These extracted features serve as a representation of the underlying movement
behavior of the GPS route.
In this thesis, a combination of geometric (e.g., bounding box area, point
density) and dynamic (e.g., heading change) features were used to represent
each waste collection tracking.

\subsection{Clustering Algorithms}
\begin{quote}
  ``Clustering is a useful tool in data science. It is a method for
  finding cluster structure in a data set that is characterized by
  the greatest similarity within the same cluster and the
  greatest dissimilarity between different
  clusters.''\cite{sinaga_pdf_2024}
\end{quote}

\subsubsection{Density-Based Clustering with DBSCAN}

\textit{DBSCAN} (Density-Based Algorithm for Discovering clusters in Large
Spatial Databases with Noise) was
introduced by Martin Ester, Hans-Peter Kriegel, Jörg Sander, and Xiowei Xu as
an algorithm to
identify
clusters of arbitrary shape in spatial databases and distinguish noise. It
relies on the notion of density-reachability among points based on a distance
threshold \textit{Eps} and a minimum number of points
\textit{MinPts}.\cite{ester_density-based_nodate}

Let \textit{D} be a database of points and let \textit{dist(p, q)} be the
distance between points \textit{p} and \textit{q} (typically Euclidean).

\begin{itemize}
  \item The \textbf{Eps-neighborhood} of a point $p$ is defined as:
        \[
          N_{\textit{Eps}}(p) = \{q \in D \mid \textit{dist(p, q)} \leq
          \textit{Eps} \}
        \]

  \item A point $p$ is a \textbf{core point} if:
        \[
          |N_{\textit{Eps}}(p)| \geq \textit{MinPts}
        \]

  \item A point $q$ is \textbf{directly density-reachable} from $p$ if:
        \[
          q \in N_{\textit{Eps}}(p) \textit{ and } p \textit{ is a core point}
        \]

        \begin{figure}[htbp]
          \centering

          \includegraphics[width=0.7\textwidth]{Figures/background/dbscan_core_points_and_border_points.png}
          \caption{DBSCAN: Core points and border points
            \cite{ester_density-based_nodate}}
          \label{fig:dbscan-reachability-and-connectivity}
        \end{figure}

  \item A point $q$ is \textbf{density-reachable} from $p$ if there is a chain
        of points
        $p_1, p_2, ..., p_n$ such that $p_1 = p$, $p_n = q$, and each $p_{i+1}$
        is
        directly
        density-reachable from $p_i$.

  \item Two points $p$ and $q$ are \textbf{density-connected} if there exists a
        point
        $o$ such that both $p$ and $q$ are density-reachable from $o$.
\end{itemize}

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.7\textwidth]{Figures/background/dbscan_density_reachability_connectivity.png}
  \caption{DBSCAN: (a) Density-reachability and (b) density-connectivity
    \cite{ester_density-based_nodate}}
  \label{fig:dbscan-reachability-and-connectivity}
\end{figure}
\FloatBarrier

This concept allows DBSCAN to detect clusters without
requiring the number of clusters as input, unlike other clustering algorithms
such as K-Means and CLARANS, making it effective for outlier detection.
\cite{ester_density-based_nodate}

\subsubsection{K-Means Clustering}
K-Means is the first unsupervised algorithm used to cluster data in an
euclidean space and is still widely used to partition a dataset
$ \{x_1, x_2, \dots, x_n\}$ of size
$n$ into $k \leq n$ sets $S = \{S_1, S_2, \dots, S_k\}$ \cite{sinaga_pdf_2024}

The goal to minimize the within-cluster sum of squares (WCSS) can be shown with
following function:
\[
  J = \sum_{i=1}^{k} \sum_{x_j \in S_i} \| x_j - \mu_i \|^2
\]~\cite{sinaga_pdf_2024}

The implementation of the algorithm uses an iterative refinement technique,
also known as Lloyd's Algorithm.
An initial set of \textit{k} means is selected, randomly or are more
sophisticatedly initialized in adaptations such as K-Means++.
Then the algorithm repeats the following two steps until the assignments do not
change and K-Means therefore converges~\cite{sinaga_pdf_2024}:

\begin{enumerate}
  \item \textbf{Assignment:} Assign each data point to the cluster with the
        least squared Euclidean distance (mean):
        \[
          S_i = \{x_j : \| x_j - \mu_i \|^2 \leq \| x_j - \mu_l \|^2, \,
          \forall \, 1
          \leq l \leq k\}
        \]
  \item \textbf{Update:} Update the means of data points assigned to each
        cluster:
        \[
          \mu_i = \frac{1}{|S_i|} \sum_{x_j \in S_i} x_j
        \]
\end{enumerate}

\subsubsection{Combining DBSCAN and K-Means}
DBSCAN can be used to identify anomalies by dividing the data set into two
clusters. Cluster 0 with the valid data and cluster -1 with anomalies. Using
the output of DBSCAN and removing the detected anomaly cluster -1 as the input
for K-Means, a more effective partitioning of the data into k number of groups
can be achieved.
Without DBSCAN, K-Means clustering will likely assign one cluster to outliers
of faulty data.
In the context of waste collection, where GPS signals may be faulty, this
combined method improves the robustness of the clustering by eliminating
irregular datapoints, which do not show regular operation of the vehicle.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.7\textwidth]{Figures/background/k-means-and-DBSCAN-clustering-results-on-Chainlink-data-set.png}
  \caption{Comparison: K-Means, DBSCAN clustering algorithms
    \cite{liang_graph-based_2024}}
  \label{fig:dbscan_against_k-means}
\end{figure}
\FloatBarrier

\subsection{Machine Learning Model Deployment with APIs}

To enable the integration of machine learning models into other applications,
model deployment via Application Programming Interfaces (APIs) is a crucial
step.
APIs allow the model to be exposed and queried by external systems and return
predictions based on the user-provided inputs.
This thesis uses FastAPI to deploy the trained model and follows modern
software engineering
principles~\cite{voron_building_2023,noauthor_deploying_nodate}.

\section{Related Work}
While much research concerned with GPS-Data analysis and classification
problems
focused on transportation mode detection and trajectory mining. Few studies
have investigated the classification of urban structure
based on waste collection trackings.
This thesis addresses this gap by proposing a pipeline to distinguish between
urban, suburban, town and rural structures from tracking data alone.

\subsection{Urban structure analytics}
The structure of urban areas has been analysed in many studies.
Song et al., proposes a framework that uses access structure to describe and
evaluate spatial relationships between streets, plots and
buildings~\cite{song_access_2021}. While Zhou et al., proposes a big data
approach to
analyse the urban spatial structures of different
areas~\cite{zhou_research_2022}.

\subsection{Transportation Mode Prediction with Feature Engineering}
Etemad, Soared and Matwin~\cite{etemad_predicting_2018} propose a five step
framework to predict the
underlying transportation mode from GPS traces. The framework
includes in order the preparation of data, point feature extraction (e.g.,
distance, speed, bearing rate and its derivatives), trajectory feature
extraction (e.g., min, max, mean and std., percentiles), noise removal and
normalization.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{Figures/related_work/etemad_pipeline.png}
  \caption{Steps of the framework for predicting of transportation
    modes proposed by Etemad et al.~\cite{etemad_predicting_2018}}
  \label{fig:etemad_framework_prediction}
\end{figure}
\FloatBarrier

Their framework achieves competitive results with the
classifier scoring 96.5\% accuracy and a f1 score of 96.3\%. The study shows
the
importance of noise reduction and feature engineering when working with GPS
trace data.~\cite{etemad_predicting_2018}

While their work focuses on the classification of transportation modes (e.g.,
walking, bike, car, etc.), the techniques used for extracting features and
noise reduction, are also applicable for the structural classification of waste
collection routes, which is the focus of this thesis.

\subsection{Clustering of GPS Data using Distance-based Features}
Koh et al.~\cite{koh_clustering_2022} present a framework to cluster users
based on their movement patterns captured via an application on their mobile
phones.
The authors propose a new metric, \textit{Daily Characteristic Distance
  (DCD)},
which is used to create a fair comparison between working and nonworking users
on workdays and offdays and extract features in combination with
\textit{Origin-Destination (OD)} matrix features ~\cite{koh_clustering_2022}.

The features derived from the DCD are combined with OD matrix
features
and are used in a K-Means clustering algorithm to group the users into three
behavior groups. The study analyses the resulting clusters with two newly
proposed
metrics: \textit{User Commonality} (percentage of users that visited each
point of interest (POI) category) and \textit{Average Frequency} (average
percentage of trips to each POI category).~\cite{koh_clustering_2022}

\begin{figure}[htbp]
  \centering

  \includegraphics[width=\textwidth]{Figures/related_work/koh_clustering_framwork_flowchart.png}
  \caption{Steps of the framework proposed by Koh et
    al.~\cite{koh_clustering_2022}}
  \label{fig:koh_clustering_framework}
\end{figure}
\FloatBarrier

The work of Koh et al. shows that meaningful patterns can be extracted from GPS
data using unsupervised clustering methods. This approach is highly relevant
for this thesis,
as it demonstrates that structural characteristics can be derived from
engineered features
and effectively used for clustering and classification. Although the papers
focus is on
GPS traces of individual people and captures data with mobile phones, the
underlying methods can
be applied for identifying patterns and similarities in GPS track data
collected by
waste collection vehicles.

\chapter{Problem Definition and Solution Approach}
This chapter introduces the core problem addressed by the thesis, describes the
dataset used, and outlines the solution approach. The proposed method involves
analyzing GPS tracking data from waste collection vehicles, extracting features
and using machine
learning techniques to classify the structure of waste collection vehicle
trackings.

\section{Big Picture}

GPS trackings are collected by waste collection vehicles during real-world
operation in the DACH region.
These raw trackings are compressed by \textit{infeo GmbH} to reduce storage
size while
keeping necessary route information, and then saved in a centralized database.
The data provided is a subset approved by \textit{infeo GmbH} for analysis in
this thesis.

The aim of this thesis is to develop a pipeline that can automatically classify
GPS trackings to four categories (e.g., rural, town, suburban and urban).

The proposed solution follows a high-level workflow with the following steps:

\begin{enumerate}
  \item \textbf{Data Preperation:} Data is cleaned and filtered to remove
        invalid or incomplete trackings.
  \item \textbf{Feature Extraction:} Meaningful features such as point density
        and bounding box area are calculated for each tracking.
  \item \textbf{Outlier Detection:} Secondary detection of invalid trackings
        and trackings that significantly deviate from expected patterns are
        removed
        using density-based clustering (DBSCAN).
  \item \textbf{Clustering:} The cleaned tracking data is grouped into four
        clusters based on similarity using K-Means.
  \item \textbf{Classification:} A Classifier is trained to generalize the
        clustering results and allow automated classification of new trackings.
  \item \textbf{API:} The classifier is integrated into an API to allow the
        classification of trackings via REST calls.
\end{enumerate}

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.8\textwidth]{Diagrams/drawio/big_picture.png}
  \caption{High-level overview of training the GPS track classifier}
  \label{fig:big_picture_diagram}
\end{figure}
\FloatBarrier

\section{Description of the Dataset}
Gaining an understanding of the provided data structure is crucial for
identifying the available information and its limitations.
This analysis helps identify which types of
information can be extracted from the dataset and enables the derivation of
meaningful features.

\subsection{Overview}
The dataset used is a collection of GPS tracking data collected by
waste collection vehicles from various waste collection businesses and provided
by \textit{infeo GmbH}. It represents real-world data
collected during regular waste collection operation in the DACH region.

\subsection{Source and Collection Method}
The data was obtained by the onboard tracking systems installed by
\textit{infeo GmbH},
which collects GPS coordinates in regular intervals during regular operation.
Each tracking represents a complete waste collection route taken and includes
metadata as well as a list of GPS coordinates.

\subsection{Structure of the Data}
Each dataset entry represents a single recorded route referred to as
\textit{tracking} and contains metadata as well as a ordered list of GPS
coordinates.

Each tracking contains the following relevant fields:
\begin{table}[H]
  \centering
  \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Field}       & \textbf{Type}  & \textbf{Description}
    \\
    \hline
    \texttt{id}          & Integer        & Unique identifier of the tracking
    entry.

    \\
    \hline
    \texttt{name}        & String         & Name of the tracking (randomized
    for anonymization)
    identification.
    \\
    \hline
    \texttt{description} & String         & Route metadata, often includes
    internal codes.
    \\
    \hline
    \texttt{recorded}    & DateTime       & Start date and time of the
    tracking.
    \\
    \hline
    \texttt{length}      & Float          & Total length of the route in
    kilometers.
    \\
    \hline
    \texttt{duration}    & Integer        & Total duration of the tracking.
    \\
    \hline
    \texttt{vehicleId}   & Integer / Null & ID of the vehicle (nullified for
    anonymization).
    \\
    \hline
    \texttt{tourId}      & Integer / Null & ID of the associated tour
    (nullified for anonymization).
    \\
    \hline
    \texttt{isExported}  & Boolean        & Flag indicating if the tracking was
    exported.
    \\
    \hline
    \texttt{editState}   & Integer        & Edit state used by the system.
    \\
    \hline
  \end{tabular}
  \label{tab:tracking_structure}
  \caption{Structure of a Tracking Entry}
\end{table}

Each GPS point contains the following relevant fields:
\begin{table}[H]
  \centering
  \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Field}         & \textbf{Type} & \textbf{Description}
    \\
    \hline
    \texttt{id}            & Integer       & Unique identifier of the GPS
    point.
    \\
    \hline
    \texttt{time}          & DateTime      & Timestamp of when the point was
    recorded.
    \\
    \hline
    \texttt{latitude}      & Float         & Latitude coordinate.
    \\
    \hline
    \texttt{longitude}     & Float         & Longitude coordinate.
    \\
    \hline
    \texttt{speed}         & Float         & Instantaneous speed at the time.
    \\
    \hline
    \texttt{heading}       & Float         & Direction of movement in degrees.
    \\
    \hline
    \texttt{sequence}      & Integer       & Position of the point in the
    tracking
    sequence.
    \\
    \hline
    \texttt{metaTag}       & Integer       & Custom metadata tag.
    \\
    \hline
    \texttt{metaValue}     & String        & Value associated with the metadata
    tag.
    \\
    \hline
    \texttt{pointBaseType} & Integer       & Internal point type used by the
    system.
    \\
    \hline
  \end{tabular}
  \caption{Structure of a GPS Waypoint Entry}
  \label{tab:gps_point_structure}
\end{table}

\subsection{Size and Coverage}

The dataset consists of 101,353 individual trackings with a combined number of
123,785,460 waypoints.
Trackings were recorded by waste collection vehicles during real-world
operation in the DACH
region.

\subsection{Data compression}
The dataset used in this thesis is pre-compressed internaly by \textit{infeo
  GmbH} while keeping essential route information~\cite{noauthor_route_nodate}:

\begin{enumerate}
  \item \textbf{Delete same waypoints:} Consecutive waypoints with identical
        GPS position are deleted.
  \item \textbf{Delete waypoints with distance smaller than (x):} Delete all
        Consecutive waypoints with a distance to each other of less than (x)
        meters.
  \item \textbf{Delete waypoints with path curvature smaller than
          (x)\textsuperscript{s}:} For every group of three consecutive
        waypoints \( A \), \( B \), and \( C \), the middle point \( B \) is
        deleted if
        all the following criteria are met:
        \begin{enumerate}
          \item The distance \( \overline{AB} \) is less than a specified
                threshold (e.g., 100 meters), \textbf{or} \( \overline{BC} \)
                is less than the
                threshold.
          \item The distance \( \overline{AC} \) is less than a specified
                threshold (e.g., 1000 meters).
          \item The change in heading \( \alpha \) between segments \(
                \overline{AB} \) and \( \overline{BC} \) is smaller than a
                defined angle (e.g.,
                \(10^\circ\)).
        \end{enumerate}
        \begin{figure}[H]
          \centering
          \vspace{-1em}

          \includegraphics[width=0.7\textwidth]{Figures/problem_definition/Aufzeichnune-komprimieren-winkelreduktion.png}
          \caption{Waypoint curvature calculation used for
            compression~\cite{noauthor_route_nodate}}
          \label{fig:waypoint_curvature_calculation}
          \vspace{-1em}
        \end{figure}
        \FloatBarrier

\end{enumerate}

\subsection{Limitations}

A significant limitation of this study is due to the nature of the dataset.
While the dataset is extensive, offering a large sum of trackings, many prove
to be irrelevant or misleading for analysis.
According to discussion with \textit{infeo GmBH} and manual visual inspection,
the primary cause of these data issues is the manual operation of the tracking
device in the waste collection vehicles.

The most common issues were:

\begin{itemize}
  \item \textbf{Depot-only trackings:} Many trackings were exclusively
        recording the movement in the vehicle parking facility, capturing no
        real waste
        collection operation.
  \item \textbf{Non-operational trackings:} Tracking devices were left active
        for long periods of time, outside of operational hours, such as
        overnight,
        resulting in long trackings with little movement.
  \item \textbf{Large Signal gaps:} Some trackings suffered from significant
        gaps in the GPS track, resulting from signal loss of the tracker or
        possibly from the compression step introduced by \textit{infeo GmbH}.
\end{itemize}

As a consequence of these issues in the dataset, a comprehensive preprocessing
and filtering was necessary to ensure the quality of the dataset used for
analysis and
classification.
While the cleaning process was designed to be as robust as possible, it is
possible that some faulty trackings persist in the filtered dataset and that
some valid trackings were wrongfully discarded.

\section{Dataset Analysis}
Before a classification model can be developed, it is important to understand
the underlying data it will be trained on.
This section presents an exploratory data analysis of the cleaned dataset with
the goal of identifying relationships of extracted features that help separate
the
four categories.

\subsection{Sample Analysis}

A small, manually selected sample of 8 tracking routes was selected for initial
exploratory data analysis. Each route was inspected on the
\textit{AWM-Map-Tool} and
then categorized into one of the four area type labels: \texttt{URBAN},
\texttt{SUBURBAN}, \texttt{TOWN} or \texttt{RURAL}. Each Label is represented
by 2 tracking routes in the sample data to
ensure a balanced representation.

Feature extraction was performed to calculate route-level metrics such as
bounding box area, point density and average
distance between points.

The goal of this sample is to explore patterns, validate assumptions, and
identify features useful for future automatic classification.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=\textwidth]{Figures/sample_tracking_routes_mapgrid.png}
  \caption{Mapgrid for selected sample trackings}
  \label{fig:sample_mapgrid}
\end{figure}
\FloatBarrier
The mapgrid (Figure \ref{fig:sample_mapgrid}) shows spatial layout of each
tracking route overlayed on a visual
map. Each subplot corresponds to a single tracking and is colorcoded with the
assigned label (RURAL=Red, SUBURBAN=Orange, TOWN=Blue, URBAN=Green). This
visual representation clearly shows the difference in route shapes and sizes
between the four different area types, which are arranged from highest to
lowest urban density.

\textbf{Urban:}
\begin{itemize}
  \item Routes are geographically compact and highly localized.
  \item Movement appears dense with short travel distances between stops.
  \item Often confined to a small cluster of city blocks or neighborhoods.
\end{itemize}

\textbf{Suburban:}
\begin{itemize}
  \item Routes are more spread out than urban routes, but still relatively
        dense.
  \item Represent transition areas between dense city cores and surrounding
        areas.
  \item Moderately spaced routes, covering residential areas with more open
        space and lower building density.
\end{itemize}

\textbf{Town:}
\begin{itemize}
  \item Routes are fairly spread out but less spread out than rural areas.
  \item More dispered than suburban areas, with less consistent street layout.
  \item Collection points are more spaced out, and routes often span small
        settlements with connecting streets.
\end{itemize}

\textbf{Rural:}
\begin{itemize}
  \item Routes are long and span large geographical areas.
  \item Stops are widely spaced, often connecting small, isolated settlements.
  \item The shape and path vary significantly, often following main roads
        between distant collection points.
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{Figures/sample_pairplot.png}
  \caption{Pairplot of selected GPS route features grouped by area label}
  \label{fig:sample_pairplot}
\end{figure}
\FloatBarrier

The pairplot (Figure \ref{fig:sample_pairplot}) visualizes the relationships
between all pairs of extracted features.
While the small sample size limits the generalization, the plot suggests clear
seperation between the extremese \texttt{URBAN} and \texttt{RURAL}, especially
in dimensions such as point density and bounding box area.

The main utility of this plot lies in
confirming basic trends: urban routes appear denser and more compact, while
rural routes cover larger spatial areas with lower density. Suburban and town
routes fall in between but exhibit more overlap and variability.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{Figures/sample_correlation_matrix.png}
  \caption{Correlation Matrix of selected GPS route features grouped by area
    label}
  \label{fig:sample_correlation_matrix}
\end{figure}
\FloatBarrier

The correlation matrix (Figure \ref{fig:sample_correlation_matrix}) highlights
expected and useful relationship between features.
Strong positive correlation between \texttt{length}, \texttt{duration},
\texttt{num\_points} and \texttt{bbox\_area} exists, as these features all
describe the scale of the
tracking.
\texttt{point\_density} shows a strong negative correlation with those same
features, indicating that shorter, more compact routes have denser GPS point
coverage.
\texttt{straightness} and \texttt{mean\_heading\_change} show a moderate
correlation to other features, suggesting that they add additional orthogonal
information about the geometric characteristics of the tracking.

These relationships validate the consistency of the data and show the value of
using this sample as a baseline weighting for future stages in the pipeline.

\begin{figure}[h]
  \centering

  \includegraphics[width=\textwidth]{Figures/sample_point_density_boxplot.png}
  \caption{Boxplot of point density grouped by area label}
  \label{fig:sample_boxplot}
\end{figure}
\FloatBarrier

The point density boxplots for each label shows a clear difference between the
labels. Urban trackings appear to have the highest density and rural trackings
the lowest, with suburban and town trackings falling in the middle with a wider
variability.

This strong monotonic pattern across labels supports that point density is a
valuable feature for clustering and classification. Other features, such as
bounding box area and average segment distance	 show similar characteristics
as shown in Chapter 5.

\section{Solution Approach}
This chapter outlines the methods used to analyse and classify the GPS tracking
data collected by waste collection vehicles.
The approach is structured in multiple stages, beginning with exploratory data
analysis, proceeding with feature extraction, data cleaning, outlier detection,
clustering and finally training a classifier.
The goal is to identify tracking patterns that allow for structural
classification of trackings into four categories: Urban, Suburban, Town and
Rural.

\subsection{Exploratory Data Analysis}

The foundation of this thesis is the dataset provided by \textit{infeo GmbH}.
It contains anonymized GPS track data collected by waste collection vehicles
during real world operation. Due to its large size of more than 100,000 GPS
tracks and its anonymization, a clear picture of the data needed to be
established as the first step.
With visual examination of different random trackings a sample of eight
manually labeled trackings was gathered.
The selected trackings were labeled to four categories, two trackings per
category.

\begin{itemize}
  \item \textbf{Urban:} Dense building structures, complex road networks, and
        minimal
        spacing between stops.
  \item \textbf{Suburban:} Moderately spaced residential areas with organized
        street
        layouts.
  \item \textbf{Town:} Smaller clustered settlements with simpler road
        structures.
  \item \textbf{Rural:} Sparse housing, long roads, large distances between
        collection points.
\end{itemize}

With the manually selected trackings varying in geographical structure, a
exploratory data
analysis helped transfer the visual distinction to clear differences found in
the data of each tracking category.

\subsection{Feature Extraction from Sample Dataset}
To enable the use of machine learning algorithms, each tracking originally
represented by a consecutive list of GPS waypoints with latitude and longitude
must be transformed into feature vectors. Feature extraction methods were
applied to derive representative metrics for each tracking.

This approach is well established and used in similar studies such as the
classification
of transportation modes by Etemad et al.~\cite{etemad_predicting_2018} and
clustering of GPS data using distance-based features by Koh et
al.~\cite{koh_clustering_2022}

\subsubsection{Features Available in Trackings}

\begin{enumerate}
  \item \textbf{Length:} Total distance of the tracking, in kilometers as
        recorded in the database.
  \item \textbf{Duration:} Total time duration for the tracking, captured and
        recorded in the database.
\end{enumerate}

\subsubsection{Features Extracted from Waypoints}

\begin{enumerate}
  \item \textbf{Number of Points:} The total number of GPS waypoints recorded
        in the tracking.
  \item \textbf{Bounding Box Area:} The area of the minimum bounding box that
        encloses all latitude and longitude waypoints in one tracking.
  \item \textbf{Point density:} The number of waypoints divided by the bounding
        box area. This feature indicates how closely packed the points are.
  \item \textbf{Average Segment Distance:} The mean distance between
        consecutive waypoints, computed using geodisc distance.
  \item \textbf{Straightness:} The ratio between the geodesic distance from the
        first to the last point and the total distance of the route. Values
        close to 1
        indicate a straight path, while lower values indicate loops and
        detours.
  \item \textbf{Mean Heading Change:} The average change in bearing between
        consecutive segments of the path, in radians. It reflects how often and
        how
        severe the vehicle changes direction.
\end{enumerate}

\subsection{Filtering and Preprocessing the Full Dataset}
There are a lot of faulty datapoints that are not relevant for the
clustering, that are filtered out. Before applying machine learning methods,
extensive filtering was required to
remove invalid and irrelevant data from the dataset. These included:

\begin{enumerate}
  \item Trackings with a too low duration to be realistic collection trackings.

  \item Trackings that recorded movement only in and around a parking lot.
  \item Trackings left running overnight with no significant movement.
  \item Trackings with unrealistic GPS jumps and anomalies (possibly due to
        device errors or compression errors introduced by \textit{infeo GmbH}).
\end{enumerate}

Removing these faulty datapoints was crucial for ensuring the quality of the
clustering and reducing the computation times.

\subsection{Clustering and Pattern Discovery}
To discover patterns in the unlabeled dataset, clustering algorithms were
applied.
Initially, K-Means++ was used to cluster the data into four clusters. However,
the result showed that one cluster mostly consisted of outlier routes, with
unrealistic GPS jumps.

To solve this issue, the process was improved by detecting and removing
outliers using DBSCAN (Density-Based Spatial Clustering for Applications with
Noise). DBSCAN effectively removed most anomalies in the dataset. After
filtering the outliers with DBSCAN, K-Means clustering was applied again,
resulting clusters that represented the four defined categories better.

\subsection{Training a Classification Model}
To automatically classify new trackings into one of the four categories (Urban,
Suburban, Town, Rural), a supervised machine learning model was trained using
the labeled dataset from the clustering step.
The labeled dataset was split into training and test sets using an 80/20 split.
Evaluation of the classifier on the test set showed a high overall accuracy.
The trained classifier was saved for the later use in a sandbox API to classify
new trackings.

\subsection{API Integration}
To make the trained classification model accessible and usable in a practical
sense, the solution includes the integration of a lightweight REST API.
This enables external systems to send requests to the API endpoint, and
receive a classification result in real-time.
The API is designed to receive a \texttt{tracking\_id} and fetch the tracking
data directly from the \textit{infeo GmbH} platform, preprocess it using the
same logic as the training pipeline, and apply the Random Forest classifier to
return the predicted label.

This structure follows the development of the project, from understanding the
problem and analising the data, to buildinng and evaluating a solution to
address the objective of classifying GPS trackings into structural categories.
\chapter{Implementation}

This Chapter translates the conceptual pipeline from Chapter 3 into its
concrete Python-based implementation.
Each stage of the pipeline, from data processing to feature extraction,
clustering and classification, was implemented in modular Jupyter Notebooks
using libraries such as \texttt{pandas}, \texttt{scikit-learn}, \texttt{geopy}
and \texttt{pyarrow}.Each module was designed to run independently, allowing
for quick
experimentation and reproducibility of results.

% \section{Implementation of the Big Picture}

The
Figure~\ref{fig:big_picture_implemetation_diagram} shows a more detailed view
of the pipeline introduced int Chapter 3.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.8\textwidth]{Diagrams/drawio/big_picture_implementation.png}
  \caption{Big picture implementation pipeline}
  \label{fig:big_picture_implemetation_diagram}
\end{figure}
\FloatBarrier

\section{Data Handling and Preprocessing}
Efficient handling and preprocessing were essential to manage the large dataset
and prepare it for the feature extraction step.
This section describes the loading, filtering and preparing the raw GPS
tracking data for feature extraction.

\subsection{Data volume and loading}

The data was provided via a MySQL database, containing two main tables relevant
for this analysis.
Trackings table containing the metadata of 101,353 trackings and the waypoints
table containing the corresponding GPS waypoints of the trackings.
Due to the substantial size of database \textbf{~13.5 GB} in total, with
\textbf{~12.6 MB} from the tracking table and \textbf{~11.6 GB} from the
waypoint table,
an efficient data handling pipeline was necessary.

To handle the data at a lower scale, the filtering query was executed directly
within the database using SQL (see Listing~\ref{lst:sql-filter}). The resulting
filtered dataset was streamed in chunks of \texttt{1,000,000} rows using
\texttt{pandas.read\_sql()} and saved incrementally to a compressed Apache
Parquet file using \texttt{pyarrow}. The final Parquet file had a reduced size
of approximately \textbf{1.5 GB}.

This chunk-wise approach ensured memory efficient loading without crashing the
kernel with the limited hardware available.
The full export operation took about two hours to fully complete, with an
average processing speed of \texttt{6.40 iterations/second} (row group read and
write cycles).

\subsection{Filtering Faulty Trackings}
The raw data included many invalid or irrelevant trackings that could impact
the analysis and clustering. These trackings were removed based on these
criteria:

\begin{itemize}
  \item \textbf{Duration Filter:} Trackings shorter than 30 minutes or longer
        than 10 hours were excluded.
  \item \textbf{Length Filter:} Trackings with a total length lower than 50 km
        or above 850km were excluded.
  \item \textbf{Minimal Waypoint Count:} Trackings with less than 10 recorded
        waypoints were excluded.
  \item \textbf{Minimal Coordinate Span:} Trackings with less than 0.0005 span
        in latitude or longitude were excluded. Equaling to about 50 meters
        north-south
        and 37 meter east-west in the DACH region.
\end{itemize}

The filters were directly implemented as a SQL query executed in an jupyter
notebook. This reduced the further computational times for clustering and
training the classifier model. The SQL query implementing these filters
as follows:
\begin{lstlisting}[style=sql,caption={SQL query used for filtering the GPS tracking dataset},label={lst:sql-filter}]
  SELECT
      wp.id_tracking, wp.id, wp.time, wp.type, wp.sequence, wp.comment,
      wp.speed, wp.heading, wp.duration, wp.block_type, wp.log,
      wp.latitude, wp.longitude, wp.altitude, wp.meta_tag, wp.meta_value,
      t.length AS tracking_length,
      t.duration AS tracking_duration
  FROM waypoint wp
  JOIN tracking t ON wp.id_tracking = t.id
  WHERE
      t.duration BETWEEN 18000000000 AND 360000000000
      -- 0.5 to 10 hours
      AND t.length BETWEEN 50 AND 850  -- 50 to 850 km
      AND EXISTS (
          SELECT 1 FROM waypoint w
          WHERE w.id_tracking = t.id
          HAVING COUNT(*) > 10  -- Min. 10 waypoints
      )
      AND (
          (SELECT MAX(latitude) FROM waypoint WHERE id_tracking = t.id) -
          (SELECT MIN(latitude) FROM waypoint WHERE id_tracking = t.id)
      ) > 0.0005  -- Min. ~50m latitude span
      AND (
          (SELECT MAX(longitude) FROM waypoint WHERE id_tracking = t.id) -
          (SELECT MIN(longitude) FROM waypoint WHERE id_tracking = t.id)
      ) > 0.0005;  -- Min. ~50m longitude span
  \end{lstlisting}

In total the filtering steps reduced the dataset by 55755 (55\%) trackings.

\section{Feature Extraction}
This section describes how raw GPS tracking data was transformed into
meaningful features that enable the use of machine learning methods in later
steps.
The features were selected based on literature and domain knowledge to capture
the characteristics of the waste collection routes.
The resulting features were used for clustering and for training the supervised
classifier. Each feature was extracted using Python libraries such as
\texttt{pandas}, \texttt{numpy}, and \texttt{geopy} and stored in a CSV file.

\subsection{Available Metadata Features}
Metadata features are calculated by \textit{infeo GmbH} and directly provided
in the dataset for each tracking. They
serve as a
baseline for route length and duration.

\paragraph{Tracking length}
The total recorded travel distance in kilometers, as stored in the metadata.

\paragraph{Tracking duration}
The full duration from the first to the last recorded waypoint, in
100-nanosecond intervals.

\subsection{Computed Features from Waypoints}
The computed features enrich the metadata by describing the geometry and
dynamics of each
tracking in numerical values.
All calculations were implemented using the \texttt{geopy} library for geodesic
distances and \texttt{numpy} for vectorized operations.
The most relevant features are described below.

\paragraph{Number of points}

The total number of waypoints $n$ in a tracking:
\[
  num\_points = n
\]

\paragraph{Bounding box area}

Computed from the geodesic height $h$ and width $w$ of the minimal enclosing
rectangle:
\[
  bbox\_area = h \cdot w
\]
\[
  h = d((lat_{\min}, long_{\min}), (lat_{\max}, long_{\min})), \quad w =
  d((lat_{\min}, lon_{\min}), (lat_{\min}, long_{\max}))
\]
where $d(\cdot, \cdot)$ refers to the geodesic distance between two GPS points
(in
meters), calculated using the WGS84 ellipsoid model through the \textit{geopy}
Python library~\cite{noauthor_welcome_nodate}.

\paragraph{Point density}

Density of GPS waypoints in the bounding box:
\[
  point\_density = \frac{n}{bbox\_area + \varepsilon}, \quad
  \varepsilon = 10^{-6}
\]
where $\varepsilon$ is a small constant to avoid division by zero.

\paragraph{Average segment distance}

The average geodesic distance between consequtive waypoints:
\[
  avg\_segment\_distance = \frac{1}{n-1} \sum_{i=1}^{n-1} d(p_i, p_{i+1})
\]
where $d(\cdot, \cdot)$ refers to geodesic
distance~\cite{franti_averaging_2021}.

\paragraph{Straightness}
Ratio between the start-end distance and the total path length:
\[
  straightness = \frac{d(p_1, p_n)}{\sum_{i=1}^{n-1} d(p_i, p_{i+1})}
\]
~\cite{benhamou_how_2004}

\paragraph{Mean Heading Change}
Average angle change between consecutive direction vectors (in radians):
\[
  \delta_i = \min(|\theta_{i+1} - \theta_i|, 2\pi - |\theta_{i+1} - \theta_i|),
  \quad
  mean\_heading\_change = \frac{1}{n-2} \sum_{i=1}^{n-2} \delta_i
\]
with bearings $\theta_i$ computed via:
\[
  \theta = \arctan2\left( \sin(\Delta \lambda) \cos(\phi_2),
  \cos(\phi_1)\sin(\phi_2) - \sin(\phi_1)\cos(\phi_2)\cos(\Delta \lambda)
  \right)
\]
~\cite{etemad_predicting_2018}

\subsection{Feature Storage and Output}

The extracted features were stored in a structured CSV file, with one row per
tracking and all corresponding features. This resulting dataset forms the
basis for all future analysis, clustering and classification applications in
the next steps of the pipeline.

\begin{table}[ht]
  \centering
  \begin{tabular}{|l|l|p{6.5cm}|}
    \hline
    \textbf{Feature}                & \textbf{Unit} & \textbf{Description}
    \\
    \hline
    \texttt{num\_points}            & Count         & Number of GPS waypoints
    in a tracking
    \\
    \hline
    \texttt{bbox\_area}             & $m^2$         & Area of bounding box
    enclosing all GPS points
    \\
    \hline
    \texttt{point\_density}         & points/m$^2$  & Number of points per
    square meter
    of bounding box
    \\
    \hline
    \texttt{avg\_segment\_distance} & m             & Mean geodesic distance
    between
    consecutive waypoints
    \\
    \hline
    \texttt{straightness}           & Ratio (0–1)   & Direct distance from
    start to end /
    total distance
    \\
    \hline
    \texttt{mean\_heading\_change}  & rad           & Average absolute angle
    change
    between segments
    \\
    \hline
    \texttt{duration}               & 100 ns        & Total tracking
    duration in nanoseconds
    \\
    \hline
    \texttt{length}                 & km            & Total tracking length
    from the database
    \\
    \hline
  \end{tabular}
  \caption{Extracted features with units and descriptions}
  \label{tab:feature_units}
\end{table}

\section{Clustering Implementation}
Through clustering the unlabeled trackings were labeled, enabling the further
application of supervised machine learning in the next.
A two stage approach was used, first DBSCAN for detecting and filtering
outliers and second a K-Means clustering was applied to label the trackings.
The implemented approach used a semi-supervised K-Means clustering. By
calculating feature weights and initial centroid position for each cluster from
a manually selected sample set to improve the clustering process.

\subsection{Outlier Removal with DBSCAN}
To remove extreme outliers from the dataset, DBSCAN (Density-Based Clusering
of Applications with Noise) algorithm was used to filter outliers from the
dataset.
Outliers were assigned the cluster label of -1 and excluded from the dataset
before applying the K-Means clustering.

It was chosen for its effective noise point detection, without the need of
implementing manual logic.

Through testing and fine tuning the final implementation of DBSCAN used the
following parameters:
\begin{itemize}
  \item \texttt{eps} = 1
  \item \texttt{min\_samples} = 40
\end{itemize}

DBSCAN removed 1,539 trackings from the dataset leaving a cleaner distribution
for the K-Means clustering.
This step was crucial for removing invalid trackings especially with large GPS
gaps. Without the outlier removal, the subsequent K-Means clustering would
always assign
outliers to one class.

\subsection{Semi-Supervised Clustering with Weighted and Seeded K-Means}

To improve the interpretability and performance of clustering, a
semi-supervised approach was used to guide the K-Means algorithm. A manually
labeled subset of 8 samples, evenly distributed across the four target
categories (\texttt{URBAN}, \texttt{SUBURBAN}, \texttt{TOWN}, \texttt{RURAL}),
was utilized to derive feature weights and initialize cluster centroids. This
allowed the unsupervised clustering algorithm to be seeded with domain
knowledge.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Diagrams/drawio/implementation/clustering_pipeline.png}
  \caption{K-Means semi supervised clustering pipeline}
  \label{fig:kmeans-clustering-pipline}
\end{figure}
\FloatBarrier

\subsubsection{Feature Weighting Based on Sample Label Spread}

In order to emphasize features that varied significantly across known classes
and downweight features with less discriminative power, relative variability of
feature medians between the categories was used. Specifically, for each feature
$f_i$, the relative median range was calculated as:

\[
  w_i = \frac{max_i - min_i}{mean_i}
\]

where $max_i$, $min_i$, and $mean_i$ represent the
maximum, minimum, and mean median value of feature $f_i$ across the four
labeled classes. These weights were then normalized by dividing by the mean of
all $w_i$ to ensure comparability:

\[
  w_i^{norm} = \frac{w_i}{\frac{1}{n}\sum_{j=1}^n w_j}
\]

Finally, the weights were clipped to the range $[0.5, 2.0]$ to avoid extreme
scaling effects ~\cite{guyon_introduction_nodate}.

\subsubsection{Seeded Cluster Initialization}

The cluster centers were initialized using the scaled and weighted medians of
the labeled sample set. For each class, the feature medians were calculated,
scaled using the \texttt{StandardScaler}, and then multiplied by the learned
feature weights. The resulting $4 \times d$ matrix was used to seed the $k$
centroids of the K-Means algorithm:

\[
  \mu_k = scale(median_k) \cdot w_i^{norm}
  \quad for each k \in \{1, 2, 3, 4\}
\]

This strategy ensured that the initial centroids already reflected meaningful
differences in the data as identified by the sample set.

\subsubsection{Constrained K-Means Clustering}

The clustering was performed using the \texttt{KMeansConstrained} algorithm
with the following configuration:

\begin{itemize}
  \item Number of clusters: 4
  \item Initialization: Manual (from scaled, weighted medians)
  \item Minimum cluster size: 5\% of total data
  \item Maximum cluster size: 60\% of total data
  \item Number of restarts: 10
\end{itemize}

This method produced clusters that closely aligned with the known class
distribution and improved the stability and interpretability of the clustering
outcome compared to random initialization.

\section{Classification Model}
To predict the category of new or unlabeled GPS trackings, a classification
model was trained using the extracted and clustered features. A Random Forest
classifier was chosen due to its robustness, ability to handle high-dimensional
data, and interpretability via feature importance.

\subsection{Model Selection and Training}

The full labeled dataset, enriched with cluster labels from the K-Means
algorithm, was split into a training and a test set using a 2:1 ratio. A grid
search with 3-fold cross-validation was performed to identify the best
hyperparameters for the Random Forest model. The following parameter grid was
used:

\begin{itemize}
  \item Number of estimators: \texttt{[100, 200, 300]}
  \item Maximum depth: \texttt{[10, 15, 20]}
  \item Minimum samples split: \texttt{[2, 5]}
  \item Minimum samples leaf: \texttt{[1, 2]}
  \item Class weight: \texttt{[None, 'balanced']}
\end{itemize}

The best model was found with 300 estimators, a maximum depth of 20,
2 minimum samples split, 1 minimum sample leaf and default
class weights. The trained model achieved an accuracy of
98.3\% on the test set.

\subsection{Saving and Exporting the Classifier}

The trained Random Forest model was serialized using \texttt{joblib} and
exported as a PKL file. This model can be directly
integrated into production pipelines or reused for further research.
Predictions from the classifier were stored for visualization and evaluation
purposes in a CSV file.

\section{Integration with API}

To provide real-time classification, a FastAPI-based web service was
implemented (Figure~\ref{fig:fastapi_implementation_diagram}). The service
exposes a single endpoint which takes a
\texttt{tracking\_id} as an input, fetches the corresponding tracking data from
the \textit{infeo GmbH} API, and processes the tracking data through the same
preprocessing pipeline used during the model training.

The API loads the trained classifier from a serialized PKL file and
predicts the label of processed tracking.
The endpoint then returns the \texttt{tracking\_id} and the predicted class
label in a \textit{json} format.

Figure~\ref{fig:fastapi_docs} shows the automatically generated \textit{Swagger
  UI} documentation of the endpoint.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Diagrams/drawio/api/api_implementation.png}
  \caption{API Implementation Diagram}
  \label{fig:fastapi_implementation_diagram}
\end{figure}

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Figures/api/fastapi_documentation.png}
  \caption{Swagger UI documentation of FastAPI Classification Endpoint}
  \label{fig:fastapi_docs}
\end{figure}

\chapter{Evaluation and Discussion}
This chapter presents a comprehensive evaluation of the filtering, clustering
and
classification results.
It provides insights into the performance, limitations, and robustness of the
developed system.

\section{Definition of the data sets used for the evaluation}

To assess the quality of the clustering and classification steps, various
datasets at different stages of the pipeline were used.
The final labeled dataset was split into training and test sets using a 2:1
ratio to evaluate the classifier's generalization ability.

\section{Evaluation of the Results}
This section provides the results of each step in the pipeline, highlighting
numerical results and visual representations of classified trackings.

\subsection{Filtering Results}
Each Filter step in the SQL statement reduces the dataset by this many
trackings:
\begin{table}[ht]
  \centering
  \begin{tabular}{|l|r|r|r|}
    \hline
    \textbf{Filter Step}     & \textbf{Remaining Trackings} &
    \textbf{Removed}
                             &
    \textbf{Reduction (\%)}
    \\
    \hline
    All trackings            & 101353                       & --
                             & --
    \\
    Duration filter          & 66477                        &
    34876
                             &
    34.410\%
    \\
    Length filter            & 45668                        &
    20809
                             &
    31.303\%
    \\
    Minimal Waypoints filter & 45599                        &
    69
                             &
    0.151\%
    \\
    Min Lat/Long span filter & 45598                        &
    1
                             &
    0.002\%
    \\
    \hline
    \textbf{Total Remaining} & \textbf{45598}               &
    \textbf{55755}
                             &
    \textbf{55.011\%}
    \\
    \hline
  \end{tabular}
  \caption{Tracking reduction per filtering step}
  \label{tab:filtering_summary}
\end{table}
\FloatBarrier

The filtering was effective at reducing the amount of faulty trackings in the
dataset, but could not filter out all of them.
The latitude and longitude span suggested by \textit{infeo GmbH} did not filter
out many trackings. This could be due to the filtering of stationary trackings
from the filters applied before the coordinate span filter, or indicate the
need to increase the minimum span.

\subsection{Clustering Results}

The DBSCAN clustering algorithm was used to remove noise points and outliers,
resulting in the removal of 1,539 trackings.
The PCA projection in Figure~\ref{fig:pca_dbscan} shows the detected outlier
cluster (-1), sbusequently removed resulting in a cleaner structure for the
K-Means clustering.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Figures/dbscan_diagram_feature_data.png}
  \caption{PCA Projection of DBSCAN clustering for noise removal}
  \label{fig:pca_dbscan}
\end{figure}
\FloatBarrier

The feature weights calulated from the manually selected sample data showed
that \texttt{bbox\_area}, \texttt{point\_density},
\texttt{straigthness} and \texttt{length} were the most informative features.
The concrete values are depipicted
in Figure ~\ref{fig:feature_weights_for_kmeans}.

Weighted K-Means clustering with custom initial centroids produced four
distinct clusters. Each cluster was mapped to a label (\texttt{0-URBAN},
\texttt{1-SUBURBAN}, \texttt{2-TOWN}, \texttt{3-RURAL}) based on feature
statistic and visual inspection.
The PCA projection in Figure ~\ref{fig:pca_kmeans} visualized the resulting
cluster structure, with a final silhouette score of \textbf{0.2621} indicates a
moderate clustering
separation.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Figures/feature_weights.png}
  \caption{Feature Weights used for K-Means clustering}
  \label{fig:feature_weights_for_kmeans}
\end{figure}

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Figures/kmeans_diagram_feature_data.png}
  \caption{PCA Projection of K-Means clustering}
  \label{fig:pca_kmeans}
\end{figure}
\FloatBarrier

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Figures/classifier/shap_summary_for_all_classes.png}
  \caption{SHAP Summary for all Classes}
  \label{fig:shap_all_classes}
\end{figure}

% map visualization of clustered trackings by K-Means
\begin{figure}[p]
  \centering

  \begin{subfigure}[b]{0.495\textwidth}
    \centering

    \includegraphics[width=\textwidth]{Figures/clustering_map/clustering_result_map_rural_area1.png}
    \caption{Lower Bavaria}
    \label{fig:clustering_map_visulaization_rural}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.495\textwidth}
    \centering

    \includegraphics[width=\textwidth]{Figures/clustering_map/clustering_result_map_konstanz_area_town1.png}
    \caption{Thurgau: Kreuzlingen and Konstanz}
    \label{fig:clustering_map_visulaization_konstanz}
  \end{subfigure}

  \vspace{1cm}

  \begin{subfigure}[b]{0.495\textwidth}
    \centering

    \includegraphics[width=\textwidth]{Figures/clustering_map/clustering_result_map_linz_urban1.png}
    \caption{Upper Austria: Linz}
    \label{fig:clustering_map_visulaization_linz}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.495\textwidth}
    \centering

    \includegraphics[width=\textwidth]{Figures/clustering_map/clustering_result_map_vorarlberg_closeup.png}
    \caption{Vorarlberg}
    \label{fig:clustering_map_visulaization_vorarlberg}
  \end{subfigure}

  \caption{Map Visualization of Clustered Trackings (Red: \texttt{URBAN},
    Orange: \texttt{SUBURBAN}, Blue: \texttt{TOWN}, Green: \texttt{RURAL})}
  \label{fig:clstering_map_visualizations}
\end{figure}
\FloatBarrier

\subsection{Classifier Results}

A Random Forest classifier was trained with hyperparameter tuning.
The model achieved high performance on the test set: Accuracy \textbf{98.3\%},
Macro F1-score: \textbf{98.1\%}, Weighted F1-score \textbf{98.3\%} and Cohen's
Kappa \textbf{97.3\%}.
The classifier showed balanced performance across all four classes, with
precision and recall values above \textbf{97\%} for all classes.

The feature importance analysis (Figure
~\ref{fig:feature_importance_random_forest})
highlighted \texttt[length], \texttt{bbox\_area}, \texttt{point\_density} and
\texttt{num\_points} as key contributing features.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Figures/classifier/confusion_matric_label_prediction.png}
  \caption{Confusion Matrix of Random Forest Classifier}
  \label{fig:confusion_matrix_random_forest}
\end{figure}

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Figures/classifier/feature_importance_random_forest.png}
  \caption{Feature Importance Barchart of Random Forest Classifier}
  \label{fig:feature_importance_random_forest}
\end{figure}

The mean feature values across all four classes (Figure
~\ref{fig:mean_feature_value_matrix_by_class}) confirm a monotonic
relationships
between classes in increasing rurality (e.g.,\texttt{URBAN} to
\texttt{SUBURBAN} to \texttt{TOWN} to
\texttt{RURAL})
for the features
\texttt{bbox\_area}, \texttt{point\_density}, \texttt{avg\_segment\_distance}
and \texttt{length}.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Figures/classifier/feature_values_normalized.png}
  \caption{Normalized Mean Feature Values by Predicted Class}
  \label{fig:mean_feature_value_matrix_by_class}
\end{figure}
\FloatBarrier

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Figures/classifier/pca_projection_test_set.png}
  \caption{PCA Projection of Test Set with Predicted Labels}
  \label{fig:pca_projection_test_set}
\end{figure}
\FloatBarrier

\begin{figure}[htbp]
  \centering

  \includegraphics[width=0.9\textwidth]{Figures/classifier/shap_summary_for_all_classes.png}
  \caption{SHAP Summary for all Classes}
  \label{fig:shap_all_classes}
\end{figure}

\begin{figure}[p]
  \centering

  \begin{subfigure}[b]{0.495\textwidth}
    \centering

    \includegraphics[width=\textwidth]{Figures/classifier/shap/shap_summary_for_URBAN.png}
    \caption{Urban}
    \label{fig:shap_urban}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.495\textwidth}
    \centering

    \includegraphics[width=\textwidth]{Figures/classifier/shap/shap_summary_for_SUBURBAN.png}
    \caption{Suburban}
    \label{fig:shap_suburban}
  \end{subfigure}

  \vspace{1cm}

  \begin{subfigure}[b]{0.495\textwidth}
    \centering

    \includegraphics[width=\textwidth]{Figures/classifier/shap/shap_summary_for_TOWN.png}
    \caption{Town}
    \label{fig:shap_town}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.495\textwidth}
    \centering

    \includegraphics[width=\textwidth]{Figures/classifier/shap/shap_summary_for_RURAL.png}
    \caption{Rural}
    \label{fig:shap_rural}
  \end{subfigure}

  \caption{SHAP summary plots for all classes}
  \label{fig:shap_all_classes}
\end{figure}

Finally four random trackings from each category were selected from the
classified test set and visualized on map segments
~\ref{fig:four_final_predictions_on_testset}, validating the structural and
spatial differences of the labels.

\begin{figure}[htbp]
  \centering

  \includegraphics[width=\textwidth]{Figures/classifier/four_final_predictions_per_class.png}
  \caption{Sample Predictions on Test Set}
  \label{fig:four_final_predictions_on_testset}
\end{figure}
\FloatBarrier

\section{Reflection on the Results}

The clustering and classification pipeline effectively distinguishes between
urban structures based on GPS tracking data, with the classifier achieving high
accuracy with over \textbf{97\%} in all
key metrics. While the clustering silhouette score was moderate, visual and
statistical inspection validate the coherence of the clusters.

Despite the promising results, some limitations of the evaluation setup must be
considered. The classifier was trained and tested using labels generated
through semi-supervised K-Means clustering. While the clustering was guided by
meaningful initial centroids and validated visually and statistically, the
resulting labels do not represent objective ground truth. Consequently, the
classifier's high accuracy of \textbf{98.3\%} reflects strong alignment with
the underlying clustering logic rather than verified real-world
classifications. The model has yet to be validated against expert-labeled or
GIS-based reference data, and its generalizability beyond the current dataset
remains an open question.

The negative silhouette score on the test set shows some significant
overlap between classes in the high-dimensional space. This could
be adressed in future iterations by reducing te number of clusters (e.g.,
merging \texttt{SUBURBAN} and \texttt{TOWN}) or by incorporating additional
features from OpenStreetMap.

The features \texttt{bbox\_area}, \texttt{point\_density} and
\texttt{duration},
initially deemed suitable for distinction between classes, because of their
monotonic
behavior, were confirmed to be indicative discriminators.
Furthermore, the
classification results show that \texttt{avg\_segment\_distance} and
\texttt{mean\_heading\_change} also follow monotonic behavior among classes,
reinforcing the effectiveness of this pipeline.

Overall, the presented method offers a reproducible and scalable approach for
GPS-based
route classification, with potential applications in waste collection
planning, infrastructure analysis, and beyond. With further validation and
integration of additional geospatial data, the framework has the potential to
evolve into a robust decision support tool.

\section{Expert Feedback}

During the development of the thesis, a meeting with Reischer Florian the
founder and CEO of \texttt{infeo GmbH} was held.
The of the meeting was to present intermediate results and gather feedback on
the applicability of the developed pipeline in a production setting.

Reischer emphasized that the classification of the GPS trackings into
structural categories is a solid starting point, the dataset in this thesis
alone is not sufficient for the comparison between new and existing service
areas. He pointed out, that for a final deployable solution, additional data
sources, such as detailed road networks or geographic information such as
population, road and intersection count are needed.
With that additional information, accurate comparisons between existing
trackings and new areas seem possible for automating the planning support.

A key point of discussion was the feature \texttt{point\_density}, which showed
strong discriminative power in the analysis and played a central role in both
clustering and classification (see
Figures~\ref{fig:sample_pairplot,fig:feature_weights_for_kmeans,fig:feature_importance_random_forest}).

However, Reischer was concerned about the robustness of calculated features
such as \texttt{point\_density}, as these features rely on the amount of points
present in the dataset, which is impacted by the internal compression by
\textit{infeo GmbH}.
This compression removed points with the same coordinates and thinned out point
on long straights to reduce filesizes.

While \texttt{point\_density} proved to be useful in this thesis, its
reliability might be limited.
Comparison with non-compressed trackings could determine how the compression
step impacts featuress reliant on the amount of waypoints, such as
\texttt{poin\_density}.

Overall, while further progress is necessary for a live deployment, Reischer
concluded that this thesis gatheres important information and builds a strong
foundation for the long-term goal of automating area comparison and suggesting
planning parameters.

\chapter{Conclusion}

This thesis demonstrates that it is feasible to classify the structure of road
networks
using only GPS tracking data collected by waste collection vehicles.
A robust pipeline to categorize trackings into four distinct urban structure
types: \texttt{URBAN}, \texttt{SUBURBAN}, \texttt{TOWN} and \texttt{RURAL} was
developed using feature engineering, semi-supervised clustering, and supervised
classification.

\section{Future Directions}

Several opportunities exist to improve and extend this thesis.

One promising direction involves the integration of OpenStreetMap (OSM) data to
augment the GPS based features with real-world structural information. On the
one hand this could improve the classifier's ability to differentiate between
trackings with similar GPS structure, while on the other hand enabling the
comparison with areas where no data is collected.

Additionally, enhancing the preprocessing pipeline with a filter to remove
transit segmets between depots and services areas in the trackings can focus
the
analysis on the actual waste collection behavior.

Improving the selected sample for the semi-supervised clustering process, both
in terms of amount and variation of manually labeled trackings
could improve the feature weights and initial centroids heavily affecting the
clustering process.

Finally, deploying the trained clasifier as a REST API, would enable
waste management companies to automatically classify GPS trackings in
real-time,
potentially enabling smarter planning, anomaly detection, and route
optimization.

\section{Limitations}

Despite the promising results of the classification pipeline, several
limitations must be acknoladged.

Firstly, the dataset used in this thesis is not raw GPS data but rather a
compressed and preprocessed version provided by \textit{infeo GmbH}.
While this process is necessary for storage and performance, it might have
removed information that could improve the clustering and classification
accuracy and reveal more fine grained distinction between the categories.

Secondly, while the dataset provides accurate GPS coordinates, the metadata is
limited or unreliable. Attributes such as speed are missing entirely, and
loading and
unloading events were only sparsely available. As a result only GPS-based
features
were used for feature extraction, potentially limiting the detection of
behavior patterns
initially deemed as valuable differentiators between classes, such as distance
between loadings of the vehicles.

Furthermore, the dataset is not suitable for a direct comparison with
OpenStreetMap (OSM) street data. Such a comparison would require the enrichment
of the dataset with strucutral data from OSM or a complete derivation of route
segments from OSM.

Lastly, the classification pipeline relies heavily on the semi-supervised
clustering
to generate labels. While it is effective for this dataset, it might require
adjustments
when extending the dataset to other cities and regions.

\section{Final Remarks}
Overall, this thesis provides a practical framework for analysing and
classifying GPS tracking data in the waste management domain. It bridges the
gap between raw GPS data and operational insights,
laying the foundation for smarter, data-driven waste management systems.

\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\printbibliography

% \chapter*{[evtl. Anhang]}  % evtl. ersetzen mit \chapter*{Anhang}
% \addcontentsline{toc}{chapter}{[evtl. Anhang]}
% % evtl. ersetzen mit \addcontentsline{toc}{chapter}{Anhang}
% Formatvorlage für den Fließtext.

% \section{Use of AI tools}

\appendix
\chapter{Data Sheet on the Use of AI}
\begin{table}[h]
  \centering
  \resizebox{\textwidth}{!}{%
    \begin{tabular}{|p{4cm}|c|c|p{7cm}|}
      \hline
      \textbf{Creatiion process Working steps} & \textbf{have
        used AI}
                                               & \textbf{AI
      tool(s)}                                 &
      \textbf{Experiences / recommendations / irritations}
      \\
      \hline
      Find a topic idea                        & no
                                               & -
                                               & -
      \\
      \hline
      Narrow down topic / Formulate question   & no
                                               & -
                                               & -
      \\
      \hline
      Find sources                             & yes
                                               & OpenAI GPT-4o, Perplexity.ai
                                               & Helped identify relevant
      keywords and
      topic clusters.
      \\
      \hline
      Explain terms                            & yes
                                               & OpenAI GPT-4o
                                               & Useful for quick definitions
      and
      simple explanations.
      \\
      \hline
      Design text structure                    & yes
                                               & OpenAI GPT-4o
                                               & Good for outlining sections.
      Required manual adjustments.
      \\
      \hline
      Have content read aloud                  & no
                                               & -
                                               & -
      \\
      \hline
      Translate content                        & yes
                                               & DeepL
                                               & Very good at translating
      between english and german.
      \\
      \hline
      Dictate content                          & no
                                               & -
                                               & -
      \\
      \hline
      Paraphrase content, summarise            & yes
                                               & OpenAI GPT-4o
                                               & Helpful to generate
      concise summaries of long text.
      \\
      \hline
      Write introduction                       & yes
                                               & OpenAI GPT-4o
                                               & Provided inspiration but
      required rewording.
      \\
      \hline
      Write main chapter                       & yes
                                               & OpenAI GPT-4o
                                               & Used for structuring and
      rephrasing, not full writing.
      \\
      \hline
      Write a summary                          & yes
                                               & OpenAI GPT-4o
                                               & Used to summarize main points
      effectively.
      \\
      \hline
      Obtain text feedback                     & yes
                                               & OpenAI GPT-4o
                                               & Used to review tone, clarity,
      and consistency.
      \\
      \hline
      Revise text statement                    & yes
                                               & OpenAI GPT-4o
                                               & Helpful for reformulating
      statements.
      \\
      \hline
      Revise text formulation                  & yes
                                               & OpenAI GPT-4o
                                               & Polished sentences and
      improved flow.
      \\
      \hline
      Correct text formally                    & yes
                                               & OpenAI GPT-4o
                                               & Assisted with grammar and
      punctuation checking.
      \\
      \hline
      Code generation                          & yes
                                               & OpenAI GPT-4o, Claude Sonnet 4
                                               & Assisted with generating code
      and fixing bugs
      \\
      \hline
    \end{tabular}%
  }
  \caption{Data sheet on the use of AI}
\end{table}

\chapter*{Affidavit}
\addcontentsline{toc}{chapter}{Affidavit}
I hereby declare in lieu of oath that I have written this Bachelor
thesis independently and without the use of aids other than those specified.
The passages taken directly or indirectly from other sources
directly or indirectly from other sources are marked as such. The thesis has
not been
neither in the same nor in a similar form to any other examination authority
nor has it been published.

\vspace{3cm}
\noindent
Dornbirn, on 15. May 2025\hfill Matthias Hefel

\end{document}
